{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data\n",
    "# !wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet -O ../data/fhv_tripdata_2021-01.parquet\n",
    "# !wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet -O ../data/fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet('../data/fhv_tripdata_2021-01.parquet')\n",
    "df2 = pd.read_parquet('../data/fhv_tripdata_2021-02.parquet')\n",
    "\n",
    "for df in [df1, df2]:\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 1154112\n"
     ]
    }
   ],
   "source": [
    "print(\"Q1:\", df1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: 19.167224093791006\n"
     ]
    }
   ],
   "source": [
    "print(\"Q2:\", df1.duration.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num      0.000000\n",
       "pickup_datetime           0.000000\n",
       "dropOff_datetime          0.000000\n",
       "PUlocationID              0.830307\n",
       "DOlocationID              0.140558\n",
       "SR_Flag                   1.000000\n",
       "Affiliated_base_number    0.000767\n",
       "duration                  0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: 526\n"
     ]
    }
   ],
   "source": [
    "a = len(set(df1.PUlocationID.unique()) | set(df2.PUlocationID.unique()))\n",
    "b = len(set(df1.DOlocationID.unique()) | set(df2.DOlocationID.unique()))\n",
    "print(\"Q4:\", a + b - 2) # remove nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 and Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1109826, 525), (990113, 525))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1[(df1.duration >= 1) & (df1.duration <= 60)]\n",
    "df2 = df2[(df2.duration >= 1) & (df2.duration <= 60)]\n",
    "\n",
    "\n",
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "# df1 = df1.dropna(subset=categorical)\n",
    "# df2 = df2.dropna(subset=categorical)\n",
    "df1 = df1.fillna(-1)\n",
    "df2 = df2.fillna(-1)\n",
    "\n",
    "\n",
    "# For dict vectorizer: int = ignored, str = one-hot\n",
    "df1[categorical] = df1[categorical].astype(int).astype(str)\n",
    "df2[categorical] = df2[categorical].astype(int).astype(str)\n",
    "\n",
    "train_dicts = df1[categorical].to_dict(orient='records')\n",
    "valid_dicts = df2[categorical].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer()\n",
    "dv.fit(train_dicts)\n",
    "\n",
    "X_train = dv.transform(train_dicts)\n",
    "y_train = df1.duration.values\n",
    "\n",
    "X_valid = dv.transform(valid_dicts)\n",
    "y_valid = df2.duration.values\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: 10.528519107210428\n",
      "Q6: 11.014283211658533\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "print(\"Q5:\", mean_squared_error(y_train, lr.predict(X_train), squared=False))\n",
    "print(\"Q6:\", mean_squared_error(y_valid, lr.predict(X_valid), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
